method	exam	+/-	exam-std	n-exam	+/-	n-exam-std	orig_TREC_leaderboard_rank	orig_EXAM_leaderboard_rank
Bert-ConvKNRM	0.503	+/-	0.011	0.615	+/-	0.011	 	 
Bert-ConvKNRM-50	0.605	+/-	0.011	0.743	+/-	0.009	9.000	6.000
Bert-DRMMTKS	0.366	+/-	0.013	0.447	+/-	0.015	12.000	3.000
ECNU_BM25	0.604	+/-	0.012	0.741	+/-	0.010	 	 
ECNU_BM25_1	0.602	+/-	0.011	0.738	+/-	0.010	7.500	11.000
ECNU_ReRank1	0.572	+/-	0.011	0.700	+/-	0.009	7.500	12.000
ICT-BM25	0.598	+/-	0.011	0.734	+/-	0.010	 	 
ICT-DRMMTKS	0.369	+/-	0.014	0.449	+/-	0.015	16.000	13.000
IRIT1	0.569	+/-	0.012	0.698	+/-	0.011	5.000	7.000
IRIT2	0.569	+/-	0.012	0.698	+/-	0.011	5.000	4.000
IRIT3	0.569	+/-	0.012	0.698	+/-	0.011	5.000	9.000
ReRnak2_BERT	0.623	+/-	0.010	0.765	+/-	0.009	3.000	1.000
ReRnak3_BERT	0.620	+/-	0.010	0.760	+/-	0.008	2.000	5.000
UNH-bm25-ecmpsg	0.522	+/-	0.013	0.640	+/-	0.013	11.000	10.000
UNH-bm25-rm	0.545	+/-	0.012	0.668	+/-	0.012	 	 
UNH-bm25-stem	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UNH-dl100	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UNH-dl300	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UNH-ecn	0.522	+/-	0.012	0.639	+/-	0.011	 	 
UNH-qee	0.614	+/-	0.011	0.753	+/-	0.010	 	 
UNH-tfidf-lem	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UNH-tfidf-ptsim	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UNH-tfidf-stem	0.522	+/-	0.013	0.640	+/-	0.013	 	 
UvABM25RM3	0.260	+/-	0.015	0.315	+/-	0.017	13.000	15.000
UvABottomUp1	0.209	+/-	0.011	0.252	+/-	0.013	 	 
UvABottomUp2	0.251	+/-	0.014	0.306	+/-	0.017	15.000	16.000
UvABottomUpChangeOrder	0.255	+/-	0.014	0.309	+/-	0.017	14.000	14.000
_overall_	0.811	+/-	0.008	1.000	+/-	0.000	 	 
bm25-populated	0.547	+/-	0.012	0.670	+/-	0.011	10.000	8.000
dangnt-nlp	0.609	+/-	0.012	0.747	+/-	0.011	1.000	2.000
spearman	0.869			0.869				
kendall	0.687			0.687				
 EXAM scores produced with GradeFilter(model_name=None, prompt_class='QuestionSelfRatedUnanswerablePromptWithChoices', is_self_rated=None, min_self_rating=None, question_set='genq')
 min_rating	4



