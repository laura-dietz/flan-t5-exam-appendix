method	exam	+/-	exam-std	n-exam	+/-	n-exam-std	orig_TREC_leaderboard_rank	orig_EXAM_leaderboard_rank
_overall_	0.911	+/-	0.016	1.000	+/-	0.000	 	 
p_d2q_bm25_duo	0.756	+/-	0.024	0.824	+/-	0.019	6.000	 
p_d2q_rm3_duo	0.752	+/-	0.024	0.820	+/-	0.019	7.000	 
bcai_bertl_pass	0.748	+/-	0.025	0.815	+/-	0.020	23.000	 
bigIR-T5-R	0.750	+/-	0.027	0.814	+/-	0.022	24.000	 
NLE_pr3	0.748	+/-	0.026	0.813	+/-	0.022	12.000	 
pash_f2	0.744	+/-	0.027	0.808	+/-	0.022	5.000	 
NLE_pr1	0.743	+/-	0.027	0.807	+/-	0.022	17.000	 
p_bm25rm3_duo	0.739	+/-	0.025	0.806	+/-	0.020	8.000	 
pash_f3	0.741	+/-	0.026	0.804	+/-	0.022	3.000	 
pash_f1	0.741	+/-	0.026	0.804	+/-	0.022	4.000	 
rr-pass-roberta	0.741	+/-	0.027	0.804	+/-	0.022	22.000	 
nlm-ens-bst-2	0.743	+/-	0.027	0.804	+/-	0.021	28.000	 
pinganNLP1	0.741	+/-	0.027	0.804	+/-	0.022	15.000	 
pinganNLP2	0.741	+/-	0.027	0.804	+/-	0.022	13.000	 
pinganNLP3	0.741	+/-	0.027	0.804	+/-	0.022	14.000	 
TUW-TK-2Layer	0.739	+/-	0.025	0.802	+/-	0.020	34.000	 
pash_r3	0.739	+/-	0.027	0.801	+/-	0.023	1.000	 
pash_r2	0.739	+/-	0.027	0.801	+/-	0.023	2.000	 
NLE_pr2	0.737	+/-	0.026	0.801	+/-	0.022	16.000	 
bigIR-T5xp-T5-F	0.735	+/-	0.027	0.800	+/-	0.023	27.000	 
RMIT-Bart	0.737	+/-	0.026	0.800	+/-	0.022	10.000	 
bigIR-DCT-T5-F	0.733	+/-	0.027	0.798	+/-	0.024	21.000	 
pash_r1	0.735	+/-	0.028	0.795	+/-	0.024	11.000	 
nlm-ens-bst-3	0.735	+/-	0.027	0.795	+/-	0.021	29.000	 
fr_pass_roberta	0.733	+/-	0.029	0.793	+/-	0.025	20.000	 
CoRT-electra	0.731	+/-	0.028	0.793	+/-	0.024	9.000	 
2	0.730	+/-	0.027	0.792	+/-	0.022	25.000	 
bert_6	0.726	+/-	0.026	0.790	+/-	0.021	37.000	 
nlm-prfun-bert	0.730	+/-	0.027	0.789	+/-	0.023	32.000	 
bigIR-BERT-R	0.728	+/-	0.027	0.789	+/-	0.023	19.000	 
1	0.728	+/-	0.028	0.787	+/-	0.023	18.000	 
relemb_mlm_0_2	0.724	+/-	0.027	0.785	+/-	0.023	31.000	 
bigIR-T5-BERT-F	0.720	+/-	0.028	0.782	+/-	0.024	26.000	 
nlm-bert-rr	0.722	+/-	0.029	0.780	+/-	0.024	30.000	 
p_d2q_bm25	0.713	+/-	0.027	0.774	+/-	0.022	35.000	 
indri-fdm	0.709	+/-	0.026	0.769	+/-	0.021	43.000	 
bl_bcai_mdl1_vt	0.707	+/-	0.029	0.765	+/-	0.024	40.000	 
indri-lmds	0.702	+/-	0.028	0.760	+/-	0.023	47.000	 
TUW-TK-Sparse	0.700	+/-	0.028	0.758	+/-	0.023	33.000	 
CoRT-bm25	0.694	+/-	0.027	0.756	+/-	0.023	38.000	 
indri-sdm	0.698	+/-	0.027	0.756	+/-	0.022	48.000	 
bcai_class_pass	0.694	+/-	0.028	0.753	+/-	0.024	41.000	 
p_d2q_bm25rm3	0.693	+/-	0.029	0.753	+/-	0.026	36.000	 
terrier-InL2	0.693	+/-	0.026	0.751	+/-	0.022	44.000	 
terrier-DPH	0.689	+/-	0.030	0.743	+/-	0.026	52.000	 
terrier-BM25	0.683	+/-	0.029	0.738	+/-	0.024	45.000	 
bl_bcai_mdl1_vs	0.681	+/-	0.030	0.738	+/-	0.026	42.000	 
CoRT-standalone	0.676	+/-	0.032	0.733	+/-	0.031	39.000	 
bm25_bert_token	0.667	+/-	0.029	0.723	+/-	0.026	51.000	 
TF_IDF_d_2_t_50	0.663	+/-	0.029	0.720	+/-	0.026	53.000	 
DLH_d_5_t_25	0.650	+/-	0.033	0.705	+/-	0.031	46.000	 
p_bm25	0.650	+/-	0.031	0.704	+/-	0.028	50.000	 
med_1k	0.646	+/-	0.030	0.698	+/-	0.028	55.000	 
p_bm25rm3	0.637	+/-	0.033	0.689	+/-	0.031	49.000	 
DoRA_Large_1k	0.633	+/-	0.032	0.685	+/-	0.029	56.000	 
small_1k	0.635	+/-	0.033	0.683	+/-	0.031	54.000	 
DoRA_Small	0.285	+/-	0.041	0.300	+/-	0.042	57.000	 
DoRA_Large	0.278	+/-	0.041	0.293	+/-	0.042	59.000	 
DoRA_Med	0.270	+/-	0.042	0.285	+/-	0.043	58.000	 
 EXAM scores produced with GradeFilter(model_name=None, prompt_class='QuestionSelfRatedUnanswerablePromptWithChoices', is_self_rated=None, min_self_rating=None, question_set='question-bank')
 min_rating	4
 nExam	spearman_correlation =0.89	kendall_correlation = 0.71
 exam	spearman_correlation =0.88	kendall_correlation = 0.71



