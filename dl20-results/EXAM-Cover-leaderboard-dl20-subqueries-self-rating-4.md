
| method | exam | +/- | exam-std | n-exam | +/- | n-exam-std | orig\_TREC\_leaderboard\_rank |  |  |  |  |  |  |  |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | --- | --- | --- | --- | --- |
| \_overall\_ | 0.911 | +/- | 0.016 | 1.000 | +/- | 0.000 |  |  |  |  |  |  |  |  |
| p\_d2q\_bm25\_duo | 0.756 | +/- | 0.024 | 0.824 | +/- | 0.019 | 6.000 |  |  |  |  |  |  |  |
| p\_d2q\_rm3\_duo | 0.752 | +/- | 0.024 | 0.820 | +/- | 0.019 | 7.000 |  |  |  |  |  |  |  |
| bcai\_bertl\_pass | 0.748 | +/- | 0.025 | 0.815 | +/- | 0.020 | 23.000 |  |  |  |  |  |  |  |
| bigIR-T5-R | 0.75 | +/- | 0.027 | 0.814 | +/- | 0.022 | 24.000 |  |  |  |  |  |  |  |
| NLE\_pr3 | 0.748 | +/- | 0.026 | 0.813 | +/- | 0.022 | 12.000 |  |  |  |  |  |  |  |
| pash\_f2 | 0.744 | +/- | 0.027 | 0.808 | +/- | 0.022 | 5.000 |  |  |  |  |  |  |  |
| NLE\_pr1 | 0.743 | +/- | 0.027 | 0.807 | +/- | 0.022 | 17.000 |  |  |  |  |  |  |  |
| p\_bm25rm3\_duo | 0.739 | +/- | 0.025 | 0.806 | +/- | 0.020 | 8.000 |  |  |  |  |  |  |  |
| pash\_f3 | 0.741 | +/- | 0.026 | 0.804 | +/- | 0.022 | 3.000 |  |  |  |  |  |  |  |
| pash\_f1 | 0.741 | +/- | 0.026 | 0.804 | +/- | 0.022 | 4.000 |  |  |  |  |  |  |  |
| rr-pass-roberta | 0.741 | +/- | 0.027 | 0.804 | +/- | 0.022 | 22.000 |  |  |  |  |  |  |  |
| nlm-ens-bst-2 | 0.743 | +/- | 0.027 | 0.804 | +/- | 0.021 | 28.000 |  |  |  |  |  |  |  |
| pinganNLP1 | 0.741 | +/- | 0.027 | 0.804 | +/- | 0.022 | 15.000 |  |  |  |  |  |  |  |
| pinganNLP2 | 0.741 | +/- | 0.027 | 0.804 | +/- | 0.022 | 13.000 |  |  |  |  |  |  |  |
| pinganNLP3 | 0.741 | +/- | 0.027 | 0.804 | +/- | 0.022 | 14.000 |  |  |  |  |  |  |  |
| TUW-TK-2Layer | 0.739 | +/- | 0.025 | 0.802 | +/- | 0.020 | 34.000 |  |  |  |  |  |  |  |
| pash\_r3 | 0.739 | +/- | 0.027 | 0.801 | +/- | 0.023 | 1.000 |  |  |  |  |  |  |  |
| pash\_r2 | 0.739 | +/- | 0.027 | 0.801 | +/- | 0.023 | 2.000 |  |  |  |  |  |  |  |
| NLE\_pr2 | 0.737 | +/- | 0.026 | 0.801 | +/- | 0.022 | 16.000 |  |  |  |  |  |  |  |
| bigIR-T5xp-T5-F | 0.735 | +/- | 0.027 | 0.800 | +/- | 0.023 | 27.000 |  |  |  |  |  |  |  |
| RMIT-Bart | 0.737 | +/- | 0.026 | 0.800 | +/- | 0.022 | 10.000 |  |  |  |  |  |  |  |
| bigIR-DCT-T5-F | 0.733 | +/- | 0.027 | 0.798 | +/- | 0.024 | 21.000 |  |  |  |  |  |  |  |
| pash\_r1 | 0.735 | +/- | 0.028 | 0.795 | +/- | 0.024 | 11.000 |  |  |  |  |  |  |  |
| nlm-ens-bst-3 | 0.735 | +/- | 0.027 | 0.795 | +/- | 0.021 | 29.000 |  |  |  |  |  |  |  |
| fr\_pass\_roberta | 0.733 | +/- | 0.029 | 0.793 | +/- | 0.025 | 20.000 |  |  |  |  |  |  |  |
| CoRT-electra | 0.731 | +/- | 0.028 | 0.793 | +/- | 0.024 | 9.000 |  |  |  |  |  |  |  |
| 2 | 0.73 | +/- | 0.027 | 0.792 | +/- | 0.022 | 25.000 |  |  |  |  |  |  |  |
| bert\_6 | 0.726 | +/- | 0.026 | 0.790 | +/- | 0.021 | 37.000 |  |  |  |  |  |  |  |
| nlm-prfun-bert | 0.73 | +/- | 0.027 | 0.789 | +/- | 0.023 | 32.000 |  |  |  |  |  |  |  |
| bigIR-BERT-R | 0.728 | +/- | 0.027 | 0.789 | +/- | 0.023 | 19.000 |  |  |  |  |  |  |  |
| 1 | 0.728 | +/- | 0.028 | 0.787 | +/- | 0.023 | 18.000 |  |  |  |  |  |  |  |
| relemb\_mlm\_0\_2 | 0.724 | +/- | 0.027 | 0.785 | +/- | 0.023 | 31.000 |  |  |  |  |  |  |  |
| bigIR-T5-BERT-F | 0.72 | +/- | 0.028 | 0.782 | +/- | 0.024 | 26.000 |  |  |  |  |  |  |  |
| nlm-bert-rr | 0.722 | +/- | 0.029 | 0.780 | +/- | 0.024 | 30.000 |  |  |  |  |  |  |  |
| p\_d2q\_bm25 | 0.713 | +/- | 0.027 | 0.774 | +/- | 0.022 | 35.000 |  |  |  |  |  |  |  |
| indri-fdm | 0.709 | +/- | 0.026 | 0.769 | +/- | 0.021 | 43.000 |  |  |  |  |  |  |  |
| bl\_bcai\_mdl1\_vt | 0.707 | +/- | 0.029 | 0.765 | +/- | 0.024 | 40.000 |  |  |  |  |  |  |  |
| indri-lmds | 0.702 | +/- | 0.028 | 0.760 | +/- | 0.023 | 47.000 |  |  |  |  |  |  |  |
| TUW-TK-Sparse | 0.7 | +/- | 0.028 | 0.758 | +/- | 0.023 | 33.000 |  |  |  |  |  |  |  |
| CoRT-bm25 | 0.694 | +/- | 0.027 | 0.756 | +/- | 0.023 | 38.000 |  |  |  |  |  |  |  |
| indri-sdm | 0.698 | +/- | 0.027 | 0.756 | +/- | 0.022 | 48.000 |  |  |  |  |  |  |  |
| bcai\_class\_pass | 0.694 | +/- | 0.028 | 0.753 | +/- | 0.024 | 41.000 |  |  |  |  |  |  |  |
| p\_d2q\_bm25rm3 | 0.693 | +/- | 0.029 | 0.753 | +/- | 0.026 | 36.000 |  |  |  |  |  |  |  |
| terrier-InL2 | 0.693 | +/- | 0.026 | 0.751 | +/- | 0.022 | 44.000 |  |  |  |  |  |  |  |
| terrier-DPH | 0.689 | +/- | 0.030 | 0.743 | +/- | 0.026 | 52.000 |  |  |  |  |  |  |  |
| terrier-BM25 | 0.683 | +/- | 0.029 | 0.738 | +/- | 0.024 | 45.000 |  |  |  |  |  |  |  |
| bl\_bcai\_mdl1\_vs | 0.681 | +/- | 0.030 | 0.738 | +/- | 0.026 | 42.000 |  |  |  |  |  |  |  |
| CoRT-standalone | 0.676 | +/- | 0.032 | 0.733 | +/- | 0.031 | 39.000 |  |  |  |  |  |  |  |
| bm25\_bert\_token | 0.667 | +/- | 0.029 | 0.723 | +/- | 0.026 | 51.000 |  |  |  |  |  |  |  |
| TF\_IDF\_d\_2\_t\_50 | 0.663 | +/- | 0.029 | 0.720 | +/- | 0.026 | 53.000 |  |  |  |  |  |  |  |
| DLH\_d\_5\_t\_25 | 0.65 | +/- | 0.033 | 0.705 | +/- | 0.031 | 46.000 |  |  |  |  |  |  |  |
| p\_bm25 | 0.65 | +/- | 0.031 | 0.704 | +/- | 0.028 | 50.000 |  |  |  |  |  |  |  |
| med\_1k | 0.646 | +/- | 0.030 | 0.698 | +/- | 0.028 | 55.000 |  |  |  |  |  |  |  |
| p\_bm25rm3 | 0.637 | +/- | 0.033 | 0.689 | +/- | 0.031 | 49.000 |  |  |  |  |  |  |  |
| DoRA\_Large\_1k | 0.633 | +/- | 0.032 | 0.685 | +/- | 0.029 | 56.000 |  |  |  |  |  |  |  |
| small\_1k | 0.635 | +/- | 0.033 | 0.683 | +/- | 0.031 | 54.000 |  |  |  |  |  |  |  |
| DoRA\_Small | 0.285 | +/- | 0.041 | 0.300 | +/- | 0.042 | 57.000 |  |  |  |  |  |  |  |
| DoRA\_Large | 0.278 | +/- | 0.041 | 0.293 | +/- | 0.042 | 59.000 |  |  |  |  |  |  |  |
| DoRA\_Med | 0.27 | +/- | 0.042 | 0.285 | +/- | 0.043 | 58.000 |  |  |  |  |  |  |  |
| EXAM scores produced with GradeFilter(model\_name=None, prompt\_class='QuestionSelfRatedUnanswerablePromptWithChoices', is\_self\_rated=None, min\_self\_rating=None, question\_set='question-bank') |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
| min\_rating | 4 |  |  |  |  |  |  |  |  |  |  |  |  |  |
| nExam | spearman\_correlation =0.89 | kendall\_correlation = 0.71 |  |  |  |  |  |  |  |  |  |  |  |  |
| exam | spearman\_correlation =0.88 | kendall\_correlation = 0.71 |  |  |  |  |  |  |  |  |  |  |  |  |

